





import os
os.getcwd()


import pandas as pd 
import numpy as np
import math
import matplotlib.pyplot as plt 
import sklearn.neighbors 
import sklearn.metrics 
import seaborn as sns





data = pd.read_csv('data/wisc_bc_data.csv', delimiter = ',') 
data.info()
data.describe()





data.loc[:,'diagnosis'] = data.loc[:, 'diagnosis'].factorize()[0]
data = data.drop('id', axis=1) # dropping IDs





data['diagnosis'].value_counts()





def normalize(x):
    return (x - min(x))/(max(x) - min(x))





colsToNormalize         = data.columns[1:32] 
data[colsToNormalize]   = data[colsToNormalize].apply(normalize)

data.describe()





# ------------ korelacja --------------------
# korelacja miedzy zmiennymi, uzywam wszystkich danych 
corr_matrix = data.corr()

# Wybieram tylko jedna polowke macierzy korelacji (bo jest symetryczna)
corr_matrix = corr_matrix.where(np.tril(np.ones(corr_matrix.shape),k=-1).astype(bool))
with sns.axes_style('white'):
    f,ax = plt.subplots(figsize=(15,10))
    ax= sns.heatmap(corr_matrix,vmin=-1, vmax=1, cmap='RdBu', linewidth =.1, annot = True)
    plt.rc('xtick', labelsize=9) 
    plt.rc('ytick', labelsize=9)
    #ax.xaxis.tick_top()


y_corr = corr_matrix.loc[:,'diagnosis']
y_corr_sorted = y_corr.sort_values(ascending=False)  # sorting for clarity 





y_corr_sorted








train   = data.sample(frac=0.8,random_state=200)
y_train = train.loc[:,'diagnosis'] 

x_train = train.loc[:, train.columns != 'diagnosis']

test    = data.drop(train.index)
y_test = test.loc[:,'diagnosis'] 
y_test = y_test.to_numpy(dtype = int) # converting to numpy array, otherwise confusion matrix doesn't work 
x_test = test.loc[:, test.columns != 'diagnosis'] 

train['diagnosis'].value_counts()





print('B/M ratio, training set:')
print(train['diagnosis'].value_counts()[0]/train['diagnosis'].value_counts()[1])   

print('B/M ratio, testing set:')
print(test['diagnosis'].value_counts()[0]/test['diagnosis'].value_counts()[1])   





# create empty model with given N 
knn_model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5) 
# train model 
knn_model.fit(x_train, y_train)

# test 
test_preds = knn_model.predict(x_test)





test_preds = np.where(test_preds >= 0.5, 1, 0)





mse = sklearn.metrics.mean_squared_error(y_test, test_preds)
rmse = math.sqrt(mse)

cmap = sns.cubehelix_palette(as_cmap=True)
f, ax = plt.subplots()
points = ax.scatter(x_test.iloc[:, 2], x_test.iloc[:, 3], c=test_preds, s=50, cmap=cmap)
ax.set_title('Perimeter vs area, color by diagnosis')
ax.set_xlabel('Mean perimeter, normalized')
ax.set_ylabel('Mean area, normalized')
f.colorbar(points)
plt.show()








conf_matrix = sklearn.metrics.confusion_matrix(y_test,test_preds)
print('True negativies: {0}, false positivies: {1}, \n \
      false negatives: {2}, true positivies: {3}  '.format(conf_matrix[0,0],
      conf_matrix[0,1], conf_matrix[1,0], conf_matrix[1,1]))
  
sklearn.metrics.ConfusionMatrixDisplay(conf_matrix).plot()
plt.title('KNN - 5 neighbors')
plt.show()


print(sklearn.metrics.classification_report(y_test,test_preds))


ROC curve for the predictions:


sklearn.metrics.roc_curve(y_test, test_preds)
sklearn.metrics.RocCurveDisplay.from_predictions(
    y_test, test_preds)
plt.show()





knn_model2 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
knn_model2.fit(x_train, y_train)
test_preds2 = knn_model2.predict(x_test)
test_preds2 = np.where(test_preds2 >= 0.5, 1, 0)
conf_matrix2 = sklearn.metrics.confusion_matrix(y_test,test_preds2)

sklearn.metrics.ConfusionMatrixDisplay(conf_matrix2).plot()
plt.title('KNN - 3 neighbors')
plt.show()





knn_model3 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=12)
knn_model3.fit(x_train, y_train)
test_preds3 = knn_model3.predict(x_test)
test_preds3 = np.where(test_preds3 >= 0.5, 1, 0)
conf_matrix3 = sklearn.metrics.confusion_matrix(y_test,test_preds3)

sklearn.metrics.ConfusionMatrixDisplay(conf_matrix3).plot()
plt.title('KNN - 12 neighbors')
plt.show()



